{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Fri March 02 14:42:35 2020\n",
    "\n",
    "@author:Patricia de Melo Maia\n",
    "cohort: 5 - Valencia\n",
    "    \n",
    "    A) Introduction:\n",
    "    Apprentice Chef, Inc. is an innovative company with a unique spin on cooking at home. \n",
    "    After three years serving customers across the San Francisco Bay Area, the executives \n",
    "    at Apprentice Chef have come to realize that over 90% of their revenue comes from customers\n",
    "    that have been ordering meal sets for 12 months or less. Given this information, they would\n",
    "    like to better understand how much revenue to expect from each customer within their first \n",
    "    year of orders. Thus, they have hired you on a full-timecontract to analyze their data, \n",
    "    develop your top insights, and build a machine learning model to predict revenue over the \n",
    "    first year of each customerâ€™s life cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Inicialization #########################################################################################\n",
    "##########################################################################################################\n",
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # enhanced data visualization\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "import sklearn.linear_model # linear models\n",
    "import gender_guesser.detector as gender # gender detection\n",
    "import sklearn.neighbors # KNN for Regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "          \n",
    "# setting pandas print options\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "\n",
    "# specifying file name\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "# reading the file \n",
    "df = pd.read_excel(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Dataset Exploration ####################################################################################\n",
    "##########################################################################################################\n",
    "#First lines\n",
    "#df.head(n = 5)\n",
    "\n",
    "# Information about each variable\n",
    "#df.info()\n",
    "\n",
    "# descriptive statistics\n",
    "#df.describe().round(2)\n",
    "\n",
    "#Checking Missing Value Analysis and Imputation\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I imported the libraries, after, uploaded the file and then, and, then, check the information in the dataset. Checking the first 5 lines of dataset we see there are more information in the column name, like the relation between some users. Checking the info of the dataset we can see that most of the information are interger(22), there are three float and four objects. Checking the descrictive statistic information, we can see that all the user mande contact with customer service. Also, most people is registered with a mobile phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                REVENUE   R-squared:                       0.641\n",
      "Model:                            OLS   Adj. R-squared:                  0.636\n",
      "Method:                 Least Squares   F-statistic:                     142.7\n",
      "Date:                Sat, 07 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        23:45:16   Log-Likelihood:                -15460.\n",
      "No. Observations:                1946   AIC:                         3.097e+04\n",
      "Df Residuals:                    1921   BIC:                         3.111e+04\n",
      "Df Model:                          24                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                           -178.4254    342.473     -0.521      0.602    -850.083     493.232\n",
      "df['CROSS_SELL_SUCCESS']             -61.8394     38.600     -1.602      0.109    -137.542      13.863\n",
      "df['TOTAL_MEALS_ORDERED']              5.7004      0.353     16.169      0.000       5.009       6.392\n",
      "df['UNIQUE_MEALS_PURCH']             -63.7249      6.389     -9.974      0.000     -76.255     -51.195\n",
      "df['CONTACTS_W_CUSTOMER_SERVICE']     45.5821      6.997      6.515      0.000      31.860      59.304\n",
      "df['PRODUCT_CATEGORIES_VIEWED']        8.9891      5.150      1.745      0.081      -1.111      19.089\n",
      "df['AVG_TIME_PER_SITE_VISIT']         -0.6633      0.265     -2.499      0.013      -1.184      -0.143\n",
      "df['MOBILE_NUMBER']                   39.2828     48.125      0.816      0.414     -55.100     133.666\n",
      "df['CANCELLATIONS_BEFORE_NOON']        2.8835     10.260      0.281      0.779     -17.239      23.006\n",
      "df['CANCELLATIONS_AFTER_NOON']       -45.8182     36.288     -1.263      0.207    -116.987      25.351\n",
      "df['TASTES_AND_PREFERENCES']          43.5528     34.775      1.252      0.211     -24.647     111.753\n",
      "df['MOBILE_LOGINS']                  -39.4621     29.787     -1.325      0.185     -97.881      18.957\n",
      "df['PC_LOGINS']                        7.1970     26.965      0.267      0.790     -45.687      60.081\n",
      "df['WEEKLY_PLAN']                     -0.0640      1.155     -0.055      0.956      -2.329       2.201\n",
      "df['EARLY_DELIVERIES']                 3.5929      6.748      0.532      0.594      -9.641      16.827\n",
      "df['LATE_DELIVERIES']                  4.8129      5.705      0.844      0.399      -6.375      16.001\n",
      "df['PACKAGE_LOCKER']                 -22.4869     37.332     -0.602      0.547     -95.703      50.729\n",
      "df['REFRIGERATED_LOCKER']            -22.3126     56.412     -0.396      0.692    -132.948      88.323\n",
      "df['FOLLOWED_RECOMMENDATIONS_PCT']    -0.2644      0.666     -0.397      0.692      -1.571       1.042\n",
      "df['AVG_PREP_VID_TIME']                9.3453      0.632     14.781      0.000       8.105      10.585\n",
      "df['LARGEST_ORDER_SIZE']             -96.0837     17.060     -5.632      0.000    -129.541     -62.626\n",
      "df['MASTER_CLASSES_ATTENDED']        175.1914     28.517      6.143      0.000     119.263     231.119\n",
      "df['MEDIAN_MEAL_RATING']             342.4081     42.088      8.136      0.000     259.866     424.950\n",
      "df['AVG_CLICKS_PER_VISIT']           -18.1935     13.088     -1.390      0.165     -43.861       7.474\n",
      "df['TOTAL_PHOTOS_VIEWED']              0.6937      0.099      7.009      0.000       0.500       0.888\n",
      "==============================================================================\n",
      "Omnibus:                      690.548   Durbin-Watson:                   2.024\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7737.595\n",
      "Skew:                           1.339   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.395   Cond. No.                     5.87e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.87e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################################\n",
    "#Linear Regression #######################################################################################\n",
    "##########################################################################################################\n",
    "# building a base model will all varibles\n",
    "\n",
    "lm_revenue = smf.ols(formula = \"\"\"REVENUE ~\n",
    "                                df['CROSS_SELL_SUCCESS'] +\n",
    "                                df['TOTAL_MEALS_ORDERED'] +\n",
    "                                df['UNIQUE_MEALS_PURCH'] +\n",
    "                                df['CONTACTS_W_CUSTOMER_SERVICE'] +\n",
    "                                df['PRODUCT_CATEGORIES_VIEWED'] +\n",
    "                                df['AVG_TIME_PER_SITE_VISIT'] +\n",
    "                                df['MOBILE_NUMBER'] +\n",
    "                                df['CANCELLATIONS_BEFORE_NOON'] +\n",
    "                                df['CANCELLATIONS_AFTER_NOON'] +\n",
    "                                df['TASTES_AND_PREFERENCES'] +\n",
    "                                df['MOBILE_LOGINS'] +\n",
    "                                df['PC_LOGINS'] +\n",
    "                                df['WEEKLY_PLAN'] +\n",
    "                                df['EARLY_DELIVERIES'] +\n",
    "                                df['LATE_DELIVERIES'] +\n",
    "                                df['PACKAGE_LOCKER'] +\n",
    "                                df['REFRIGERATED_LOCKER'] +\n",
    "                                df['FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "                                df['AVG_PREP_VID_TIME'] +\n",
    "                                df['LARGEST_ORDER_SIZE'] +\n",
    "                                df['MASTER_CLASSES_ATTENDED'] +\n",
    "                                df['MEDIAN_MEAL_RATING'] +\n",
    "                                df['AVG_CLICKS_PER_VISIT'] +\n",
    "                                df['TOTAL_PHOTOS_VIEWED']\"\"\",\n",
    "                                data = df)\n",
    "results = lm_revenue.fit()\n",
    "# printing the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I runned a linear regression with all the intergir (22) and float(3) to check how are the p-values between them.\n",
    "I found p-values to some of theses variables. Instead of drop them, I will flag them as binary (1-use the feature , 0-did not use it) to check if the information existence is relevante to my model. Unfortunately, this approch did not improve my model. Now I will create new variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Creating new variable #######################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "##### Dividing the avg time per site visit by total orders.\n",
    "df[\"AVG_TIME_PER_SITE_VISIT_PER_ORDER\"]= df['AVG_TIME_PER_SITE_VISIT']/df['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "##### Dividing the avg prep vid time by total orders.\n",
    "df['AVG_PREP_VID_TIME_PER_ORDER'] = df['AVG_PREP_VID_TIME']/df['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "##### Dividing the avg clicks per visit by total orders.\n",
    "df['AVG_CLICKS_PER_VISIT_PER_ORDER'] = df['AVG_CLICKS_PER_VISIT']/df['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "##### Dividing PRODUCT CATEGORIES VIEWED by total orders.\n",
    "df['PRODUCT_CATEGORIES_VIEWED_PER_ORDER'] = df['PRODUCT_CATEGORIES_VIEWED']/df['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "##### NUMBER OF RECOMMENDATION\n",
    "df[\"NUMBER_OF_RECOMMENDATION\"]= df['FOLLOWED_RECOMMENDATIONS_PCT']/100 * df['TOTAL_MEALS_ORDERED']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Ploting Histogram #######################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "objectcol = ['NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME'] #object variables\n",
    "\n",
    "#### commented for save time and output\n",
    "#for col in df.columns:\n",
    "#    if col not in objectcol:\n",
    "#        fig, ax = plt.subplots(figsize = (6, 4))\n",
    "#        sns.distplot(df[col])                 \n",
    "#        plt.xlabel(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Feature Engineering ####################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "#thresholds - Base on Histogram analysis\n",
    "#REVENUE\n",
    "#CROSS_SELL_SUCCESS\n",
    "TOTAL_MEALS_ORDERED_HI = 200\n",
    "UNIQUE_MEALS_PURCH_HI = 9\n",
    "CONTACTS_W_CUSTOMER_SERVICE_HI= 12\n",
    "CONTACTS_W_CUSTOMER_SERVICE_LO= 3\n",
    "PRODUCT_CATEGORIES_VIEWED_HI = 10\n",
    "PRODUCT_CATEGORIES_VIEWED_LO = 2\n",
    "AVG_TIME_PER_SITE_VISIT_HI= 240\n",
    "#MOBILE_NUMBER\n",
    "CANCELLATIONS_BEFORE_NOON_HI = 5\n",
    "CANCELLATIONS_AFTER_NOON_HI = 2\n",
    "#TASTES_AND_PREFERENCES \n",
    "PC_LOGINS_HI= 7\n",
    "PC_LOGINS_LO= 4\n",
    "MOBILE_LOGINS_HI= 2\n",
    "WEEKLY_PLAN_HI= 15\n",
    "EARLY_DELIVERIES_HI = 4\n",
    "LATE_DELIVERIES_HI= 7\n",
    "#PACKAGE_LOCKER => is already binary\n",
    "#REFRIGERATED_LOCKER  => is already binary\n",
    "#FOLLOWED_RECOMMENDATIONS_PCT\n",
    "AVG_PREP_VID_TIME_HI= 280\n",
    "LARGEST_ORDER_SIZE_HI = 7.5\n",
    "MASTER_CLASSES_ATTENDED_HI = 2\n",
    "#MEDIAN_MEAL_RATING \n",
    "AVG_CLICKS_PER_VISIT_HI=18\n",
    "AVG_CLICKS_PER_VISIT_LO=8\n",
    "TOTAL_PHOTOS_VIEWED_HI= 200\n",
    "AVG_TIME_PER_SITE_VISIT_PER_ORDER_HI= 8\n",
    "AVG_PREP_VID_TIME_PER_ORDER_HI = 7.5\n",
    "AVG_CLICKS_PER_VISIT_PER_ORDER_HI = 0.7\n",
    "PRODUCT_CATEGORIES_VIEWED_PER_ORDER_HI= 0.25\n",
    "NUMBER_OF_RECOMMENDATION_HI= 80\n",
    "\n",
    "\n",
    "#TOTAL_MEALS_ORDERED ############################################################################################\n",
    "\n",
    "df['T_TOTAL_MEALS_ORDERED'] = 0\n",
    "condition_hi = df.loc[0:,'T_TOTAL_MEALS_ORDERED'][df['TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_HI]\n",
    "\n",
    "df['T_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#UNIQUE_MEALS_PURCH ##############################################################################################\n",
    "\n",
    "df['T_UNIQUE_MEALS_PURCH'] = 0\n",
    "condition_hi = df.loc[0:,'T_UNIQUE_MEALS_PURCH'][df['UNIQUE_MEALS_PURCH'] > UNIQUE_MEALS_PURCH_HI]\n",
    "\n",
    "df['T_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "#CONTACTS_W_CUSTOMER_SERVICE #####################################################################################\n",
    "\n",
    "df['T_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = df.loc[0:,'T_CONTACTS_W_CUSTOMER_SERVICE'][df['CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_HI]\n",
    "condition_lo = df.loc[0:,'T_CONTACTS_W_CUSTOMER_SERVICE'][df['CONTACTS_W_CUSTOMER_SERVICE'] < CONTACTS_W_CUSTOMER_SERVICE_LO]\n",
    "\n",
    "\n",
    "df['T_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "df['T_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_lo,value = 1,inplace = True)\n",
    "\n",
    "#PRODUCT_CATEGORIES_VIEWED - HIGHER AND LOWER LIMITS ##############################################################\n",
    "\n",
    "df['T_PRODUCT_CATEGORIES_VIEWED'] = 0\n",
    "condition_hi = df.loc[0:,'T_PRODUCT_CATEGORIES_VIEWED'][df['PRODUCT_CATEGORIES_VIEWED'] > PRODUCT_CATEGORIES_VIEWED_HI]\n",
    "condition_lo = df.loc[0:,'T_PRODUCT_CATEGORIES_VIEWED'][df['PRODUCT_CATEGORIES_VIEWED'] < PRODUCT_CATEGORIES_VIEWED_LO]\n",
    "\n",
    "df['T_PRODUCT_CATEGORIES_VIEWED'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "df['T_PRODUCT_CATEGORIES_VIEWED'].replace(to_replace = condition_lo,value = 1,inplace = True)\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT #########################################################################################\n",
    "\n",
    "df['T_AVG_TIME_PER_SITE_VISIT'] = 0\n",
    "condition_hi = df.loc[0:,'T_AVG_TIME_PER_SITE_VISIT'][df['AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_HI]\n",
    "\n",
    "df['T_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#CANCELLATIONS_BEFORE_NOON #########################################################################################\n",
    "\n",
    "df['T_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "condition_hi = df.loc[0:,'T_CANCELLATIONS_BEFORE_NOON'][df['CANCELLATIONS_BEFORE_NOON'] > CANCELLATIONS_BEFORE_NOON_HI]\n",
    "\n",
    "df['T_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#CANCELLATIONS_AFTER_NOON ###########################################################################################\n",
    "\n",
    "df['T_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "condition_hi = df.loc[0:,'T_CANCELLATIONS_AFTER_NOON'][df['CANCELLATIONS_AFTER_NOON'] > CANCELLATIONS_AFTER_NOON_HI]\n",
    "\n",
    "df['T_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "#PC_LOGINS - HIGHER AND LOWER LIMITS #############################################################################\n",
    "\n",
    "df['T_PC_LOGINS'] = 0\n",
    "condition_hi = df.loc[0:,'T_PC_LOGINS'][df['PC_LOGINS'] > PC_LOGINS_HI]\n",
    "condition_lo = df.loc[0:,'T_PC_LOGINS'][df['PC_LOGINS'] < PC_LOGINS_LO]\n",
    "\n",
    "df['T_PC_LOGINS'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "df['T_PC_LOGINS'].replace(to_replace = condition_lo,value = 1,inplace = True)\n",
    "\n",
    "#MOBILE_LOGINS #####################################################################################################\n",
    "df['T_MOBILE_LOGINS'] = 0\n",
    "condition = df.loc[0:,'T_MOBILE_LOGINS'][df['MOBILE_LOGINS'] > MOBILE_LOGINS_HI]\n",
    "\n",
    "df['T_MOBILE_LOGINS'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "# WEEKLY_PLAN ######################################################################################################\n",
    "df['T_WEEKLY_PLAN'] = 0\n",
    "condition = df.loc[0:,'T_WEEKLY_PLAN'][df['WEEKLY_PLAN'] > WEEKLY_PLAN_HI]\n",
    "\n",
    "df['T_WEEKLY_PLAN'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#EARLY_DELIVERIES ##################################################################################################\n",
    "df['T_EARLY_DELIVERIES'] = 0\n",
    "condition = df.loc[0:,'T_EARLY_DELIVERIES'][df['EARLY_DELIVERIES'] > EARLY_DELIVERIES_HI]\n",
    "\n",
    "df['T_EARLY_DELIVERIES'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#LATE_DELIVERIES ##################################################################################################\n",
    "df['T_LATE_DELIVERIES'] = 0\n",
    "condition_hi = df.loc[0:,'T_LATE_DELIVERIES'][df['LATE_DELIVERIES'] > LATE_DELIVERIES_HI]\n",
    "\n",
    "df['T_LATE_DELIVERIES'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#AVG_PREP_VID_TIME ###########################################################################################\n",
    "df['T_AVG_PREP_VID_TIME'] = 0\n",
    "condition_hi = df.loc[0:,'T_AVG_PREP_VID_TIME'][df['AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_HI]\n",
    "\n",
    "df['T_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "#LARGEST_ORDER_SIZE ###########################################################################################\n",
    "df['T_LARGEST_ORDER_SIZE'] = 0\n",
    "condition_hi = df.loc[0:,'T_LARGEST_ORDER_SIZE'][df['LARGEST_ORDER_SIZE'] > LARGEST_ORDER_SIZE_HI]\n",
    "\n",
    "df['T_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "#MASTER_CLASSES_ATTENDED ###########################################################################################\n",
    "df['T_MASTER_CLASSES_ATTENDED'] = 0\n",
    "condition_HI = df.loc[0:,'T_MASTER_CLASSES_ATTENDED'][df['MASTER_CLASSES_ATTENDED'] > MASTER_CLASSES_ATTENDED_HI]\n",
    "\n",
    "df['T_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "# AVG_CLICKS_PER_VISIT - HIGHER AND LOWER LIMITS ###################################################################\n",
    "df['T_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_hi = df.loc[0:,'T_AVG_CLICKS_PER_VISIT'][df['AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_HI]\n",
    "condition_lo = df.loc[0:,'T_AVG_CLICKS_PER_VISIT'][df['AVG_CLICKS_PER_VISIT'] < AVG_CLICKS_PER_VISIT_LO]\n",
    "\n",
    "df['T_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_hi,value = 1,inplace = True)\n",
    "df['T_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,value = 1,inplace = True)\n",
    "\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED ##############################################################################################\n",
    "\n",
    "df['T_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition_hi = df.loc[0:,'T_TOTAL_PHOTOS_VIEWED'][df['TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_HI]\n",
    "\n",
    "df['T_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "\n",
    "#AVG_TIME_PER_SITE_VISIT_PER_ORDER #################################################################################\n",
    "\n",
    "\n",
    "df['T_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition_hi = df.loc[0:,'T_TOTAL_PHOTOS_VIEWED'][df['TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_HI]\n",
    "\n",
    "df['T_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "\n",
    "#AVG_PREP_VID_TIME_PER_ORDER #######################################################################################\n",
    "\n",
    "df['T_AVG_PREP_VID_TIME_PER_ORDER'] = 0\n",
    "condition_hi = df.loc[0:,'T_AVG_PREP_VID_TIME_PER_ORDER'][df['AVG_PREP_VID_TIME_PER_ORDER'] > AVG_PREP_VID_TIME_PER_ORDER_HI]\n",
    "\n",
    "df['T_AVG_PREP_VID_TIME_PER_ORDER'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "#AVG_CLICKS_PER_VISIT_PER_ORDER ####################################################################################\n",
    "\n",
    "df['T_AVG_CLICKS_PER_VISIT_PER_ORDER'] = 0\n",
    "condition_hi = df.loc[0:,'T_AVG_CLICKS_PER_VISIT_PER_ORDER'][df['AVG_CLICKS_PER_VISIT_PER_ORDER'] > AVG_CLICKS_PER_VISIT_PER_ORDER_HI]\n",
    "\n",
    "df['T_AVG_CLICKS_PER_VISIT_PER_ORDER'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "#PRODUCT_CATEGORIES_VIEWED_PER_ORDER ###############################################################################\n",
    "\n",
    "df['T_PRODUCT_CATEGORIES_VIEWED_PER_ORDER'] = 0\n",
    "condition_hi = df.loc[0:,'T_PRODUCT_CATEGORIES_VIEWED_PER_ORDER'][df['PRODUCT_CATEGORIES_VIEWED_PER_ORDER'] > PRODUCT_CATEGORIES_VIEWED_PER_ORDER_HI]\n",
    "\n",
    "df['T_PRODUCT_CATEGORIES_VIEWED_PER_ORDER'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "#NUMBER_OF_RECOMMENDATION ##########################################################################################\n",
    "\n",
    "df['T_NUMBER_OF_RECOMMENDATION'] = 0\n",
    "condition_hi = df.loc[0:,'T_NUMBER_OF_RECOMMENDATION'][df['NUMBER_OF_RECOMMENDATION'] > NUMBER_OF_RECOMMENDATION_HI]\n",
    "\n",
    "df['T_NUMBER_OF_RECOMMENDATION'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Ploting Scatterplots ####################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "colm = [ 'NAME','EMAIL', 'FIRST_NAME', 'FAMILY_NAME','MOBILE_NUMBER']\n",
    "#\n",
    "#### commented for save time and output\n",
    "#for col in df.columns:\n",
    "#    if col not in colm:\n",
    "#        fig, ax = plt.subplots(figsize = (8, 6))\n",
    "#        sns.scatterplot(x = df[col],\n",
    "#                       y = df['REVENUE'],\n",
    "#                        color = 'g')\n",
    "#        plt.xlabel(col)\n",
    "#       plt.savefig('Apprentice Scatterplots1 .png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Feature Engineering ####################################################################################\n",
    "##########################################################################################################\n",
    "#thresholds - Base on scatterplot\n",
    "\n",
    "#REVENUE\n",
    "#CROSS_SELL_SUCCESS\n",
    "TOTAL_MEALS_ORDERED_CHANGE = 120\n",
    "UNIQUE_MEALS_PURCH_CHANGE = 9 \n",
    "CONTACTS_W_CUSTOMER_SERVICE_CHANGE= 10\n",
    "#PRODUCT_CATEGORIES_VIEWED\n",
    "AVG_TIME_PER_SITE_VISIT_CHANGE= 190\n",
    "#MOBILE_NUMBER\n",
    "CANCELLATIONS_BEFORE_NOON_CHANGE = 8\n",
    "CANCELLATIONS_AFTER_NOON_CHANGE = 2\n",
    "#TASTES_AND_PREFERENCES \n",
    "#PC_LOGINS\n",
    "#MOBILE_LOGINS\n",
    "WEEKLY_PLAN_CHANGE= 15\n",
    "#EARLY_DELIVERIES_HI = 4\n",
    "LATE_DELIVERIES_CHANGE= 9\n",
    "#PACKAGE_LOCKER => is already binary\n",
    "#REFRIGERATED_LOCKER  => is already binary\n",
    "#FOLLOWED_RECOMMENDATIONS_PCT\n",
    "AVG_PREP_VID_TIME_CHANGE= 210\n",
    "LARGEST_ORDER_SIZE_HI = 6\n",
    "MASTER_CLASSES_ATTENDED_HI = 2\n",
    "#MEDIAN_MEAL_RATING \n",
    "AVG_CLICKS_PER_VISIT_CHANGE= 10\n",
    "TOTAL_PHOTOS_VIEWED_CHANGE= 300\n",
    "AVG_TIME_PER_SITE_VISIT_PER_ORDER_CHARGE= 7.5\n",
    "AVG_PREP_VID_TIME_PER_ORDER_CHARGE = 4\n",
    "AVG_CLICKS_PER_VISIT_PER_ORDER_CHARGE= 0.6\n",
    "PRODUCT_CATEGORIES_VIEWED_PER_ORDER_CHARGE= 0.3\n",
    "NUMBER_OF_RECOMMENDATION_CHARGE= 60\n",
    "\n",
    "\n",
    "#TOTAL_MEALS_ORDERED ###########################################################################################\n",
    "df['TOTAL_MEALS_ORDERED_C'] = 0\n",
    "condition = df.loc[0:,'TOTAL_MEALS_ORDERED_C']\\\n",
    "                  [df['TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_CHANGE]\n",
    "\n",
    "df['TOTAL_MEALS_ORDERED_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "\n",
    "#UNIQUE_MEALS_PURCH ###########################################################################################\n",
    "df['UNIQUE_MEALS_PURCH_C'] = 0\n",
    "condition = df.loc[0:,'UNIQUE_MEALS_PURCH_C']\\\n",
    "                  [df['UNIQUE_MEALS_PURCH'] > UNIQUE_MEALS_PURCH_CHANGE]\n",
    "\n",
    "df['UNIQUE_MEALS_PURCH_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "\n",
    "\n",
    "#AVG_TIME_PER_SITE_VISIT ###########################################################################################\n",
    "df['AVG_TIME_PER_SITE_VISIT_C'] = 0\n",
    "condition = df.loc[0:,'AVG_TIME_PER_SITE_VISIT_C']\\\n",
    "                  [df['AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_CHANGE]\n",
    "\n",
    "df['AVG_TIME_PER_SITE_VISIT_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "\n",
    "##########################################################################################################\n",
    "#WEEKLY_PLAN\n",
    "#df['WEEKLY_PLAN_C'] = 0\n",
    "#condition = df.loc[0:,'WEEKLY_PLAN_C']\\\n",
    "#                  [df['WEEKLY_PLAN'] > WEEKLY_PLAN_CHANGE]\n",
    "\n",
    "#df['WEEKLY_PLAN_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "##########################################################################################################\n",
    "#AVG_CLICKS_PER_VISIT\n",
    "df['AVG_CLICKS_PER_VISIT_C'] = 0\n",
    "condition = df.loc[0:,'AVG_CLICKS_PER_VISIT_C']\\\n",
    "                  [df['AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_CHANGE]\n",
    "\n",
    "df['AVG_CLICKS_PER_VISIT_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "\n",
    "##########################################################################################################\n",
    "#AVG_PREP_VID_TIME\n",
    "df['AVG_PREP_VID_TIME_C'] = 0\n",
    "condition = df.loc[0:,'AVG_PREP_VID_TIME_C']\\\n",
    "                  [df['AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_CHANGE]\n",
    "\n",
    "df['AVG_PREP_VID_TIME_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "\n",
    "##########################################################################################################\n",
    "#TOTAL_PHOTOS_VIEWED\n",
    "df['TOTAL_PHOTOS_VIEWED_C'] = 0\n",
    "condition = df.loc[0:,'TOTAL_PHOTOS_VIEWED_C']\\\n",
    "                  [df['TOTAL_PHOTOS_VIEWED'] >TOTAL_PHOTOS_VIEWED_CHANGE]\n",
    "\n",
    "df['TOTAL_PHOTOS_VIEWED_C'].replace(to_replace = condition,value = 1, inplace= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVENUE                                  1.00\n",
      "AVG_PREP_VID_TIME                        0.64\n",
      "MEDIAN_MEAL_RATING                       0.61\n",
      "TOTAL_MEALS_ORDERED                      0.60\n",
      "TOTAL_PHOTOS_VIEWED                      0.47\n",
      "AVG_PREP_VID_TIME_C                      0.47\n",
      "MASTER_CLASSES_ATTENDED                  0.45\n",
      "LARGEST_ORDER_SIZE                       0.44\n",
      "TOTAL_MEALS_ORDERED_C                    0.42\n",
      "T_TOTAL_PHOTOS_VIEWED                    0.41\n",
      "TOTAL_PHOTOS_VIEWED_C                    0.39\n",
      "NUMBER_OF_RECOMMENDATION                 0.37\n",
      "T_TOTAL_MEALS_ORDERED                    0.35\n",
      "T_NUMBER_OF_RECOMMENDATION               0.25\n",
      "T_LARGEST_ORDER_SIZE                     0.21\n",
      "T_MASTER_CLASSES_ATTENDED                0.21\n",
      "T_AVG_PREP_VID_TIME                      0.20\n",
      "UNIQUE_MEALS_PURCH_C                     0.17\n",
      "T_UNIQUE_MEALS_PURCH                     0.17\n",
      "AVG_TIME_PER_SITE_VISIT                  0.14\n",
      "CONTACTS_W_CUSTOMER_SERVICE              0.10\n",
      "T_AVG_TIME_PER_SITE_VISIT                0.06\n",
      "T_CANCELLATIONS_AFTER_NOON               0.04\n",
      "AVG_TIME_PER_SITE_VISIT_C                0.04\n",
      "PRODUCT_CATEGORIES_VIEWED                0.03\n",
      "MOBILE_NUMBER                            0.03\n",
      "T_PRODUCT_CATEGORIES_VIEWED              0.03\n",
      "PC_LOGINS                                0.02\n",
      "CANCELLATIONS_BEFORE_NOON                0.01\n",
      "TASTES_AND_PREFERENCES                   0.01\n",
      "WEEKLY_PLAN                              0.01\n",
      "REFRIGERATED_LOCKER                     -0.00\n",
      "EARLY_DELIVERIES                        -0.00\n",
      "CROSS_SELL_SUCCESS                       0.00\n",
      "PACKAGE_LOCKER                          -0.01\n",
      "LATE_DELIVERIES                         -0.01\n",
      "FOLLOWED_RECOMMENDATIONS_PCT            -0.02\n",
      "MOBILE_LOGINS                           -0.02\n",
      "T_AVG_CLICKS_PER_VISIT                  -0.03\n",
      "T_CANCELLATIONS_BEFORE_NOON             -0.03\n",
      "CANCELLATIONS_AFTER_NOON                -0.04\n",
      "T_LATE_DELIVERIES                       -0.04\n",
      "T_CONTACTS_W_CUSTOMER_SERVICE           -0.06\n",
      "UNIQUE_MEALS_PURCH                      -0.06\n",
      "T_AVG_PREP_VID_TIME_PER_ORDER           -0.22\n",
      "T_PRODUCT_CATEGORIES_VIEWED_PER_ORDER   -0.27\n",
      "T_AVG_CLICKS_PER_VISIT_PER_ORDER        -0.36\n",
      "AVG_TIME_PER_SITE_VISIT_PER_ORDER       -0.36\n",
      "PRODUCT_CATEGORIES_VIEWED_PER_ORDER     -0.38\n",
      "AVG_PREP_VID_TIME_PER_ORDER             -0.38\n",
      "AVG_CLICKS_PER_VISIT_C                  -0.50\n",
      "AVG_CLICKS_PER_VISIT_PER_ORDER          -0.52\n",
      "AVG_CLICKS_PER_VISIT                    -0.55\n",
      "T_PC_LOGINS                               NaN\n",
      "T_MOBILE_LOGINS                           NaN\n",
      "T_WEEKLY_PLAN                             NaN\n",
      "T_EARLY_DELIVERIES                        NaN\n",
      "Name: REVENUE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################################\n",
    "#Correlation #############################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "# Checking the correlation matrix\n",
    "df_corr = df.corr().round(2)\n",
    "\n",
    "# printing (Pearson) correlations with REVENUE\n",
    "print(df_corr.loc[ : ,'REVENUE'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['REVENUE']+\n",
      "df['CROSS_SELL_SUCCESS']+\n",
      "df['NAME']+\n",
      "df['EMAIL']+\n",
      "df['FIRST_NAME']+\n",
      "df['FAMILY_NAME']+\n",
      "df['TOTAL_MEALS_ORDERED']+\n",
      "df['UNIQUE_MEALS_PURCH']+\n",
      "df['CONTACTS_W_CUSTOMER_SERVICE']+\n",
      "df['PRODUCT_CATEGORIES_VIEWED']+\n",
      "df['AVG_TIME_PER_SITE_VISIT']+\n",
      "df['MOBILE_NUMBER']+\n",
      "df['CANCELLATIONS_BEFORE_NOON']+\n",
      "df['CANCELLATIONS_AFTER_NOON']+\n",
      "df['TASTES_AND_PREFERENCES']+\n",
      "df['PC_LOGINS']+\n",
      "df['MOBILE_LOGINS']+\n",
      "df['WEEKLY_PLAN']+\n",
      "df['EARLY_DELIVERIES']+\n",
      "df['LATE_DELIVERIES']+\n",
      "df['PACKAGE_LOCKER']+\n",
      "df['REFRIGERATED_LOCKER']+\n",
      "df['FOLLOWED_RECOMMENDATIONS_PCT']+\n",
      "df['AVG_PREP_VID_TIME']+\n",
      "df['LARGEST_ORDER_SIZE']+\n",
      "df['MASTER_CLASSES_ATTENDED']+\n",
      "df['MEDIAN_MEAL_RATING']+\n",
      "df['AVG_CLICKS_PER_VISIT']+\n",
      "df['TOTAL_PHOTOS_VIEWED']+\n",
      "df['AVG_TIME_PER_SITE_VISIT_PER_ORDER']+\n",
      "df['AVG_PREP_VID_TIME_PER_ORDER']+\n",
      "df['AVG_CLICKS_PER_VISIT_PER_ORDER']+\n",
      "df['PRODUCT_CATEGORIES_VIEWED_PER_ORDER']+\n",
      "df['NUMBER_OF_RECOMMENDATION']+\n",
      "df['T_TOTAL_MEALS_ORDERED']+\n",
      "df['T_UNIQUE_MEALS_PURCH']+\n",
      "df['T_CONTACTS_W_CUSTOMER_SERVICE']+\n",
      "df['T_PRODUCT_CATEGORIES_VIEWED']+\n",
      "df['T_AVG_TIME_PER_SITE_VISIT']+\n",
      "df['T_CANCELLATIONS_BEFORE_NOON']+\n",
      "df['T_CANCELLATIONS_AFTER_NOON']+\n",
      "df['T_PC_LOGINS']+\n",
      "df['T_MOBILE_LOGINS']+\n",
      "df['T_WEEKLY_PLAN']+\n",
      "df['T_EARLY_DELIVERIES']+\n",
      "df['T_LATE_DELIVERIES']+\n",
      "df['T_AVG_PREP_VID_TIME']+\n",
      "df['T_LARGEST_ORDER_SIZE']+\n",
      "df['T_MASTER_CLASSES_ATTENDED']+\n",
      "df['T_AVG_CLICKS_PER_VISIT']+\n",
      "df['T_TOTAL_PHOTOS_VIEWED']+\n",
      "df['T_AVG_PREP_VID_TIME_PER_ORDER']+\n",
      "df['T_AVG_CLICKS_PER_VISIT_PER_ORDER']+\n",
      "df['T_PRODUCT_CATEGORIES_VIEWED_PER_ORDER']+\n",
      "df['T_NUMBER_OF_RECOMMENDATION']+\n",
      "df['TOTAL_MEALS_ORDERED_C']+\n",
      "df['UNIQUE_MEALS_PURCH_C']+\n",
      "df['AVG_TIME_PER_SITE_VISIT_C']+\n",
      "df['AVG_CLICKS_PER_VISIT_C']+\n",
      "df['AVG_PREP_VID_TIME_C']+\n",
      "df['TOTAL_PHOTOS_VIEWED_C']+\n"
     ]
    }
   ],
   "source": [
    "# Copying the file\n",
    "df_explanatory = df.copy()\n",
    "\n",
    "# formatting each explanatory variable for statsmodels\n",
    "for val in df_explanatory:\n",
    "    print(f\"df['{val}']+\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>REVENUE</td>     <th>  R-squared:         </th> <td>   0.685</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.680</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   143.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Mar 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:45:32</td>     <th>  Log-Likelihood:    </th> <td> -15331.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1946</td>      <th>  AIC:               </th> <td>3.072e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1916</td>      <th>  BIC:               </th> <td>3.089e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    29</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>  424.2416</td> <td>  294.050</td> <td>    1.443</td> <td> 0.149</td> <td> -152.450</td> <td> 1000.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['CROSS_SELL_SUCCESS']</th>               <td>  -69.2433</td> <td>   35.601</td> <td>   -1.945</td> <td> 0.052</td> <td> -139.063</td> <td>    0.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['TOTAL_MEALS_ORDERED']</th>              <td>    2.0717</td> <td>    0.617</td> <td>    3.355</td> <td> 0.001</td> <td>    0.861</td> <td>    3.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['UNIQUE_MEALS_PURCH']</th>               <td>  -66.2995</td> <td>    6.122</td> <td>  -10.830</td> <td> 0.000</td> <td>  -78.306</td> <td>  -54.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['CONTACTS_W_CUSTOMER_SERVICE']</th>      <td>  116.5224</td> <td>   10.358</td> <td>   11.250</td> <td> 0.000</td> <td>   96.209</td> <td>  136.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['PRODUCT_CATEGORIES_VIEWED']</th>        <td>    8.7671</td> <td>    5.376</td> <td>    1.631</td> <td> 0.103</td> <td>   -1.777</td> <td>   19.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['CANCELLATIONS_AFTER_NOON']</th>         <td>  -61.9703</td> <td>   33.984</td> <td>   -1.824</td> <td> 0.068</td> <td> -128.620</td> <td>    4.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['MOBILE_LOGINS']</th>                    <td>  -29.1135</td> <td>   27.906</td> <td>   -1.043</td> <td> 0.297</td> <td>  -83.843</td> <td>   25.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['LATE_DELIVERIES']</th>                  <td>   12.5390</td> <td>    7.470</td> <td>    1.678</td> <td> 0.093</td> <td>   -2.112</td> <td>   27.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['FOLLOWED_RECOMMENDATIONS_PCT']</th>     <td>   -1.0463</td> <td>    0.991</td> <td>   -1.055</td> <td> 0.291</td> <td>   -2.991</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['AVG_PREP_VID_TIME']</th>                <td>   10.8752</td> <td>    0.850</td> <td>   12.789</td> <td> 0.000</td> <td>    9.207</td> <td>   12.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['LARGEST_ORDER_SIZE']</th>               <td>  -81.3440</td> <td>   16.453</td> <td>   -4.944</td> <td> 0.000</td> <td> -113.612</td> <td>  -49.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['MASTER_CLASSES_ATTENDED']</th>          <td>  137.5602</td> <td>   26.978</td> <td>    5.099</td> <td> 0.000</td> <td>   84.650</td> <td>  190.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['MEDIAN_MEAL_RATING']</th>               <td>  208.7980</td> <td>   41.155</td> <td>    5.073</td> <td> 0.000</td> <td>  128.085</td> <td>  289.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['AVG_CLICKS_PER_VISIT']</th>             <td>  -18.9022</td> <td>   13.988</td> <td>   -1.351</td> <td> 0.177</td> <td>  -46.336</td> <td>    8.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['AVG_PREP_VID_TIME_PER_ORDER']</th>      <td> -155.9522</td> <td>   25.124</td> <td>   -6.207</td> <td> 0.000</td> <td> -205.225</td> <td> -106.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['AVG_CLICKS_PER_VISIT_PER_ORDER']</th>   <td> 1047.4912</td> <td>  232.756</td> <td>    4.500</td> <td> 0.000</td> <td>  591.009</td> <td> 1503.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['NUMBER_OF_RECOMMENDATION']</th>         <td>    1.6089</td> <td>    1.045</td> <td>    1.540</td> <td> 0.124</td> <td>   -0.440</td> <td>    3.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_UNIQUE_MEALS_PURCH']</th>             <td>  340.5680</td> <td>   84.854</td> <td>    4.014</td> <td> 0.000</td> <td>  174.152</td> <td>  506.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_PRODUCT_CATEGORIES_VIEWED']</th>      <td>  145.9807</td> <td>   59.029</td> <td>    2.473</td> <td> 0.013</td> <td>   30.214</td> <td>  261.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_AVG_TIME_PER_SITE_VISIT']</th>        <td> -237.8010</td> <td>  139.084</td> <td>   -1.710</td> <td> 0.087</td> <td> -510.572</td> <td>   34.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_PC_LOGINS']</th>                      <td> 9.996e-13</td> <td> 1.63e-13</td> <td>    6.144</td> <td> 0.000</td> <td>  6.8e-13</td> <td> 1.32e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_MOBILE_LOGINS']</th>                  <td>-4.728e-13</td> <td> 6.41e-14</td> <td>   -7.378</td> <td> 0.000</td> <td>-5.98e-13</td> <td>-3.47e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_EARLY_DELIVERIES']</th>               <td> 2.056e-13</td> <td> 5.21e-14</td> <td>    3.949</td> <td> 0.000</td> <td> 1.03e-13</td> <td> 3.08e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_LATE_DELIVERIES']</th>                <td> -121.9967</td> <td>   80.685</td> <td>   -1.512</td> <td> 0.131</td> <td> -280.237</td> <td>   36.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_AVG_PREP_VID_TIME']</th>              <td> -434.7108</td> <td>  150.174</td> <td>   -2.895</td> <td> 0.004</td> <td> -729.233</td> <td> -140.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_AVG_CLICKS_PER_VISIT']</th>           <td> -247.4746</td> <td>  148.861</td> <td>   -1.662</td> <td> 0.097</td> <td> -539.421</td> <td>   44.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_TOTAL_PHOTOS_VIEWED']</th>            <td>  128.9669</td> <td>   52.916</td> <td>    2.437</td> <td> 0.015</td> <td>   25.189</td> <td>  232.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_AVG_PREP_VID_TIME_PER_ORDER']</th>    <td>  216.1025</td> <td>  115.124</td> <td>    1.877</td> <td> 0.061</td> <td>   -9.679</td> <td>  441.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['T_AVG_CLICKS_PER_VISIT_PER_ORDER']</th> <td>-1034.9019</td> <td>  161.883</td> <td>   -6.393</td> <td> 0.000</td> <td>-1352.388</td> <td> -717.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['UNIQUE_MEALS_PURCH_C']</th>             <td>  340.5680</td> <td>   84.854</td> <td>    4.014</td> <td> 0.000</td> <td>  174.152</td> <td>  506.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['AVG_CLICKS_PER_VISIT_C']</th>           <td> -515.8060</td> <td>   68.385</td> <td>   -7.543</td> <td> 0.000</td> <td> -649.922</td> <td> -381.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['AVG_PREP_VID_TIME_C']</th>              <td>  111.0695</td> <td>   69.787</td> <td>    1.592</td> <td> 0.112</td> <td>  -25.797</td> <td>  247.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>df['TOTAL_PHOTOS_VIEWED_C']</th>            <td>  159.1868</td> <td>   65.919</td> <td>    2.415</td> <td> 0.016</td> <td>   29.907</td> <td>  288.467</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>817.246</td> <th>  Durbin-Watson:     </th> <td>   2.010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>12610.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.556</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>15.077</td>  <th>  Cond. No.          </th> <td>1.06e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.93e-25. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                REVENUE   R-squared:                       0.685\n",
       "Model:                            OLS   Adj. R-squared:                  0.680\n",
       "Method:                 Least Squares   F-statistic:                     143.8\n",
       "Date:                Sat, 07 Mar 2020   Prob (F-statistic):               0.00\n",
       "Time:                        23:45:32   Log-Likelihood:                -15331.\n",
       "No. Observations:                1946   AIC:                         3.072e+04\n",
       "Df Residuals:                    1916   BIC:                         3.089e+04\n",
       "Df Model:                          29                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                424.2416    294.050      1.443      0.149    -152.450    1000.933\n",
       "df['CROSS_SELL_SUCCESS']                 -69.2433     35.601     -1.945      0.052    -139.063       0.577\n",
       "df['TOTAL_MEALS_ORDERED']                  2.0717      0.617      3.355      0.001       0.861       3.283\n",
       "df['UNIQUE_MEALS_PURCH']                 -66.2995      6.122    -10.830      0.000     -78.306     -54.293\n",
       "df['CONTACTS_W_CUSTOMER_SERVICE']        116.5224     10.358     11.250      0.000      96.209     136.836\n",
       "df['PRODUCT_CATEGORIES_VIEWED']            8.7671      5.376      1.631      0.103      -1.777      19.311\n",
       "df['CANCELLATIONS_AFTER_NOON']           -61.9703     33.984     -1.824      0.068    -128.620       4.679\n",
       "df['MOBILE_LOGINS']                      -29.1135     27.906     -1.043      0.297     -83.843      25.615\n",
       "df['LATE_DELIVERIES']                     12.5390      7.470      1.678      0.093      -2.112      27.190\n",
       "df['FOLLOWED_RECOMMENDATIONS_PCT']        -1.0463      0.991     -1.055      0.291      -2.991       0.898\n",
       "df['AVG_PREP_VID_TIME']                   10.8752      0.850     12.789      0.000       9.207      12.543\n",
       "df['LARGEST_ORDER_SIZE']                 -81.3440     16.453     -4.944      0.000    -113.612     -49.076\n",
       "df['MASTER_CLASSES_ATTENDED']            137.5602     26.978      5.099      0.000      84.650     190.470\n",
       "df['MEDIAN_MEAL_RATING']                 208.7980     41.155      5.073      0.000     128.085     289.511\n",
       "df['AVG_CLICKS_PER_VISIT']               -18.9022     13.988     -1.351      0.177     -46.336       8.532\n",
       "df['AVG_PREP_VID_TIME_PER_ORDER']       -155.9522     25.124     -6.207      0.000    -205.225    -106.679\n",
       "df['AVG_CLICKS_PER_VISIT_PER_ORDER']    1047.4912    232.756      4.500      0.000     591.009    1503.974\n",
       "df['NUMBER_OF_RECOMMENDATION']             1.6089      1.045      1.540      0.124      -0.440       3.657\n",
       "df['T_UNIQUE_MEALS_PURCH']               340.5680     84.854      4.014      0.000     174.152     506.984\n",
       "df['T_PRODUCT_CATEGORIES_VIEWED']        145.9807     59.029      2.473      0.013      30.214     261.748\n",
       "df['T_AVG_TIME_PER_SITE_VISIT']         -237.8010    139.084     -1.710      0.087    -510.572      34.970\n",
       "df['T_PC_LOGINS']                       9.996e-13   1.63e-13      6.144      0.000     6.8e-13    1.32e-12\n",
       "df['T_MOBILE_LOGINS']                  -4.728e-13   6.41e-14     -7.378      0.000   -5.98e-13   -3.47e-13\n",
       "df['T_EARLY_DELIVERIES']                2.056e-13   5.21e-14      3.949      0.000    1.03e-13    3.08e-13\n",
       "df['T_LATE_DELIVERIES']                 -121.9967     80.685     -1.512      0.131    -280.237      36.244\n",
       "df['T_AVG_PREP_VID_TIME']               -434.7108    150.174     -2.895      0.004    -729.233    -140.188\n",
       "df['T_AVG_CLICKS_PER_VISIT']            -247.4746    148.861     -1.662      0.097    -539.421      44.471\n",
       "df['T_TOTAL_PHOTOS_VIEWED']              128.9669     52.916      2.437      0.015      25.189     232.745\n",
       "df['T_AVG_PREP_VID_TIME_PER_ORDER']      216.1025    115.124      1.877      0.061      -9.679     441.884\n",
       "df['T_AVG_CLICKS_PER_VISIT_PER_ORDER'] -1034.9019    161.883     -6.393      0.000   -1352.388    -717.416\n",
       "df['UNIQUE_MEALS_PURCH_C']               340.5680     84.854      4.014      0.000     174.152     506.984\n",
       "df['AVG_CLICKS_PER_VISIT_C']            -515.8060     68.385     -7.543      0.000    -649.922    -381.689\n",
       "df['AVG_PREP_VID_TIME_C']                111.0695     69.787      1.592      0.112     -25.797     247.936\n",
       "df['TOTAL_PHOTOS_VIEWED_C']              159.1868     65.919      2.415      0.016      29.907     288.467\n",
       "==============================================================================\n",
       "Omnibus:                      817.246   Durbin-Watson:                   2.010\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12610.876\n",
       "Skew:                           1.556   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.077   Cond. No.                     1.06e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.93e-25. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_full = smf.ols(formula = \"\"\" REVENUE  ~  df['CROSS_SELL_SUCCESS']+\n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "                                            df['TOTAL_MEALS_ORDERED']+\n",
    "                                            df['UNIQUE_MEALS_PURCH']+\n",
    "                                            df['CONTACTS_W_CUSTOMER_SERVICE']+\n",
    "                                            df['PRODUCT_CATEGORIES_VIEWED']+\n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "                                            df['CANCELLATIONS_AFTER_NOON']+\n",
    "                                            \n",
    "                                            \n",
    "                                            df['MOBILE_LOGINS']+\n",
    "                                            \n",
    "                                            \n",
    "                                            df['LATE_DELIVERIES']+\n",
    "                                            \n",
    "                                            \n",
    "                                            df['FOLLOWED_RECOMMENDATIONS_PCT']+\n",
    "                                            df['AVG_PREP_VID_TIME']+\n",
    "                                            df['LARGEST_ORDER_SIZE']+\n",
    "                                            df['MASTER_CLASSES_ATTENDED']+\n",
    "                                            df['MEDIAN_MEAL_RATING']+\n",
    "                                            df['AVG_CLICKS_PER_VISIT']+\n",
    "                                            \n",
    "                                            \n",
    "                                            df['AVG_PREP_VID_TIME_PER_ORDER']+\n",
    "                                            df['AVG_CLICKS_PER_VISIT_PER_ORDER']+\n",
    "                                            \n",
    "                                            df['NUMBER_OF_RECOMMENDATION']+\n",
    "                                            \n",
    "                                            df['T_UNIQUE_MEALS_PURCH']+\n",
    "                                            \n",
    "                                            df['T_PRODUCT_CATEGORIES_VIEWED']+\n",
    "                                            df['T_AVG_TIME_PER_SITE_VISIT']+\n",
    "                                            \n",
    "                                            \n",
    "                                            df['T_PC_LOGINS']+\n",
    "                                            df['T_MOBILE_LOGINS']+\n",
    "                                            \n",
    "                                            df['T_EARLY_DELIVERIES']+\n",
    "                                            df['T_LATE_DELIVERIES']+\n",
    "                                            df['T_AVG_PREP_VID_TIME']+\n",
    "                                            \n",
    "                                            \n",
    "                                            df['T_AVG_CLICKS_PER_VISIT']+\n",
    "                                            df['T_TOTAL_PHOTOS_VIEWED']+\n",
    "                                            df['T_AVG_PREP_VID_TIME_PER_ORDER']+\n",
    "                                            df['T_AVG_CLICKS_PER_VISIT_PER_ORDER']+\n",
    "                                            \n",
    "                                           \n",
    "                                            \n",
    "                                            df['UNIQUE_MEALS_PURCH_C']+\n",
    "                                            \n",
    "                                            df['AVG_CLICKS_PER_VISIT_C']+\n",
    "                                            df['AVG_PREP_VID_TIME_C']+\n",
    "                                            df['TOTAL_PHOTOS_VIEWED_C']\n",
    "                                                                    \"\"\",\n",
    "                                            data = df_explanatory) \n",
    "results_full = lm_full.fit()\n",
    "\n",
    "# printing the results\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "# Create the standardized file to use in linear models ###############################################################\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "#Creating df with x_variables\n",
    "x_variables = ['CROSS_SELL_SUCCESS',\n",
    "               'TOTAL_MEALS_ORDERED',\n",
    "               'UNIQUE_MEALS_PURCH',\n",
    "               'CONTACTS_W_CUSTOMER_SERVICE',\n",
    "               'PRODUCT_CATEGORIES_VIEWED',\n",
    "               'CANCELLATIONS_AFTER_NOON',\n",
    "               'MOBILE_LOGINS',\n",
    "               'LATE_DELIVERIES',\n",
    "               'FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "               'AVG_PREP_VID_TIME',\n",
    "               'LARGEST_ORDER_SIZE',\n",
    "               'MASTER_CLASSES_ATTENDED',\n",
    "               'MEDIAN_MEAL_RATING',\n",
    "               'AVG_CLICKS_PER_VISIT',\n",
    "               'AVG_PREP_VID_TIME_PER_ORDER',\n",
    "               'AVG_CLICKS_PER_VISIT_PER_ORDER',\n",
    "               'NUMBER_OF_RECOMMENDATION',\n",
    "               'T_UNIQUE_MEALS_PURCH',\n",
    "               'T_PRODUCT_CATEGORIES_VIEWED',\n",
    "               'T_AVG_TIME_PER_SITE_VISIT',\n",
    "               'T_PC_LOGINS',\n",
    "               'T_MOBILE_LOGINS',\n",
    "               'T_EARLY_DELIVERIES',\n",
    "               'T_LATE_DELIVERIES',\n",
    "               'T_AVG_PREP_VID_TIME',\n",
    "               'T_AVG_CLICKS_PER_VISIT',\n",
    "               'T_TOTAL_PHOTOS_VIEWED',\n",
    "               'T_AVG_PREP_VID_TIME_PER_ORDER',\n",
    "               'T_AVG_CLICKS_PER_VISIT_PER_ORDER',\n",
    "               'UNIQUE_MEALS_PURCH_C',\n",
    "               'AVG_CLICKS_PER_VISIT_C',\n",
    "               'AVG_PREP_VID_TIME_C',\n",
    "               'TOTAL_PHOTOS_VIEWED_C']     \n",
    "                \n",
    "#dropping\n",
    "\n",
    "#df_explanatory= df_explanatory.drop(['REVENUE'],axis=1)\n",
    "\n",
    "# preparing explanatory variable data\n",
    "appen_data   = df_explanatory.loc[ : , x_variables]\n",
    "\n",
    "# preparing response variable data\n",
    "appen_target = df_explanatory.loc[:, 'REVENUE']\n",
    "\n",
    "# preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            appen_data,\n",
    "            appen_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "# Create the standardized file to use in linear models ###############################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FITTING the scaler with housing_data\n",
    "scaler.fit(appen_data)\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(appen_data)\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled)\n",
    "\n",
    "# checking the results\n",
    "X_scaled_df.describe().round(2)\n",
    "\n",
    "X_scaled_df.columns = appen_data.columns\n",
    "\n",
    "X_scaled_df\n",
    "\n",
    "# this is the exact code we were using before\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled_df,\n",
    "            appen_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset BEFORE Scaling\n",
      "----------------------\n",
      "CROSS_SELL_SUCCESS                     0.218020\n",
      "TOTAL_MEALS_ORDERED                 3057.599946\n",
      "UNIQUE_MEALS_PURCH                     6.257663\n",
      "CONTACTS_W_CUSTOMER_SERVICE            5.201168\n",
      "PRODUCT_CATEGORIES_VIEWED              9.261178\n",
      "CANCELLATIONS_AFTER_NOON               0.186736\n",
      "MOBILE_LOGINS                          0.278218\n",
      "LATE_DELIVERIES                        7.528947\n",
      "FOLLOWED_RECOMMENDATIONS_PCT         706.023186\n",
      "AVG_PREP_VID_TIME                   2443.767133\n",
      "LARGEST_ORDER_SIZE                     2.404278\n",
      "MASTER_CLASSES_ATTENDED                0.411780\n",
      "MEDIAN_MEAL_RATING                     0.572040\n",
      "AVG_CLICKS_PER_VISIT                   5.444177\n",
      "AVG_PREP_VID_TIME_PER_ORDER            4.769608\n",
      "AVG_CLICKS_PER_VISIT_PER_ORDER         0.098951\n",
      "NUMBER_OF_RECOMMENDATION             881.777907\n",
      "T_UNIQUE_MEALS_PURCH                   0.009668\n",
      "T_PRODUCT_CATEGORIES_VIEWED            0.076318\n",
      "T_AVG_TIME_PER_SITE_VISIT              0.011679\n",
      "T_PC_LOGINS                            0.000000\n",
      "T_MOBILE_LOGINS                        0.000000\n",
      "T_EARLY_DELIVERIES                     0.000000\n",
      "T_LATE_DELIVERIES                      0.064560\n",
      "T_AVG_PREP_VID_TIME                    0.012682\n",
      "T_AVG_CLICKS_PER_VISIT                 0.010172\n",
      "T_TOTAL_PHOTOS_VIEWED                  0.166299\n",
      "T_AVG_PREP_VID_TIME_PER_ORDER          0.049208\n",
      "T_AVG_CLICKS_PER_VISIT_PER_ORDER       0.097876\n",
      "UNIQUE_MEALS_PURCH_C                   0.009668\n",
      "AVG_CLICKS_PER_VISIT_C                 0.087690\n",
      "AVG_PREP_VID_TIME_C                    0.096671\n",
      "TOTAL_PHOTOS_VIEWED_C                  0.105397\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Dataset AFTER Scaling\n",
      "----------------------\n",
      "CROSS_SELL_SUCCESS                  1.0\n",
      "TOTAL_MEALS_ORDERED                 1.0\n",
      "UNIQUE_MEALS_PURCH                  1.0\n",
      "CONTACTS_W_CUSTOMER_SERVICE         1.0\n",
      "PRODUCT_CATEGORIES_VIEWED           1.0\n",
      "CANCELLATIONS_AFTER_NOON            1.0\n",
      "MOBILE_LOGINS                       1.0\n",
      "LATE_DELIVERIES                     1.0\n",
      "FOLLOWED_RECOMMENDATIONS_PCT        1.0\n",
      "AVG_PREP_VID_TIME                   1.0\n",
      "LARGEST_ORDER_SIZE                  1.0\n",
      "MASTER_CLASSES_ATTENDED             1.0\n",
      "MEDIAN_MEAL_RATING                  1.0\n",
      "AVG_CLICKS_PER_VISIT                1.0\n",
      "AVG_PREP_VID_TIME_PER_ORDER         1.0\n",
      "AVG_CLICKS_PER_VISIT_PER_ORDER      1.0\n",
      "NUMBER_OF_RECOMMENDATION            1.0\n",
      "T_UNIQUE_MEALS_PURCH                1.0\n",
      "T_PRODUCT_CATEGORIES_VIEWED         1.0\n",
      "T_AVG_TIME_PER_SITE_VISIT           1.0\n",
      "T_PC_LOGINS                         0.0\n",
      "T_MOBILE_LOGINS                     0.0\n",
      "T_EARLY_DELIVERIES                  0.0\n",
      "T_LATE_DELIVERIES                   1.0\n",
      "T_AVG_PREP_VID_TIME                 1.0\n",
      "T_AVG_CLICKS_PER_VISIT              1.0\n",
      "T_TOTAL_PHOTOS_VIEWED               1.0\n",
      "T_AVG_PREP_VID_TIME_PER_ORDER       1.0\n",
      "T_AVG_CLICKS_PER_VISIT_PER_ORDER    1.0\n",
      "UNIQUE_MEALS_PURCH_C                1.0\n",
      "AVG_CLICKS_PER_VISIT_C              1.0\n",
      "AVG_PREP_VID_TIME_C                 1.0\n",
      "TOTAL_PHOTOS_VIEWED_C               1.0\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding labels to the scaled DataFrame\n",
    "X_scaled_df.columns = appen_data.columns\n",
    "\n",
    "#  Checking pre- and post-scaling of the data\n",
    "print(f\"\"\"\n",
    "Dataset BEFORE Scaling\n",
    "----------------------\n",
    "{pd.np.var(appen_data)}\n",
    "\n",
    "\n",
    "Dataset AFTER Scaling\n",
    "----------------------\n",
    "{pd.np.var(X_scaled_df)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7003\n",
      "Testing Score: 0.635\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "## LinearRegression ##################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING \n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# FITTING \n",
    "lr_fit = lr.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING \n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "# SCORING\n",
    "print('Training Score:', lr.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  lr.score(X_test, y_test).round(4))\n",
    "\n",
    "#saving\n",
    "lr_train_score = lr.score(X_train, y_train).round(4)\n",
    "lr_test_score  = lr.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7003\n",
      "Testing Score: 0.6348\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "## Ridge #############################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING \n",
    "ridge_model = sklearn.linear_model.Ridge()\n",
    "\n",
    "# FITTING \n",
    "ridge_fit = ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "\n",
    "print('Training Score:', ridge_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  ridge_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving\n",
    "ridge_train_score = ridge_model.score(X_train, y_train).round(4)\n",
    "ridge_test_score  = ridge_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7001\n",
      "Testing Score: 0.6336\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "## Lasso #############################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING \n",
    "lasso_model = sklearn.linear_model.Lasso()\n",
    "\n",
    "# FITTING \n",
    "lasso_fit = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING \n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "\n",
    "print('Training Score:', lasso_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  lasso_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving\n",
    "lasso_train_score = lasso_model.score(X_train, y_train).round(4)\n",
    "lasso_test_score  = lasso_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6983\n",
      "Testing Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "## SGD ##############################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING \n",
    "SGD_model = sklearn.linear_model.SGDRegressor()\n",
    "\n",
    "# FITTING \n",
    "SGD_fit = SGD_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING \n",
    "SGD_pred = lasso_model.predict(X_test)\n",
    "\n",
    "print('Training Score:', SGD_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  SGD_model.score(X_test, y_test).round(4))\n",
    "\n",
    "# saving\n",
    "SGD_train_score = SGD_model.score(X_train, y_train).round(4)\n",
    "SGD_test_score  = SGD_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6569\n",
      "Testing Score: 0.5811\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "## Elastic Net CV model object #######################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING \n",
    "elastic_model = sklearn.linear_model.ElasticNetCV()\n",
    "\n",
    "# FITTING \n",
    "elastic_fit = elastic_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING \n",
    "elastic_pred = elastic_model.predict(X_test)\n",
    "\n",
    "print('Training Score:', elastic_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  elastic_model.score(X_test, y_test).round(4))\n",
    "\n",
    "# saving\n",
    "elastic_train_score = elastic_model.score(X_train, y_train).round(4)\n",
    "elastic_test_score  = elastic_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8215\n",
      "Testing Score: 0.7347\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "## Elastic Net CV model object #######################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "# INSTANTIATING\n",
    "elastic_model = sklearn.ensemble.GradientBoostingRegressor(n_estimators=150, max_depth=2, min_samples_leaf=120)\n",
    "\n",
    "# FITTING \n",
    "elastic_fit = elastic_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING \n",
    "elastic_pred = elastic_model.predict(X_test)\n",
    "\n",
    "print('Training Score:', elastic_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  elastic_model.score(X_test, y_test).round(4))\n",
    "\n",
    "# saving\n",
    "elastic_train_score = elastic_model.score(X_train, y_train).round(4)\n",
    "elastic_test_score  = elastic_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing linear regression, lasso, SGD Regression and Elastic Net CV model object, Lasso provided the best testing score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
